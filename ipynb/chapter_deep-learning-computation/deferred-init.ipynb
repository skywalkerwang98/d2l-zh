{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 延后初始化\n",
    ":label:`sec_deferred_init`\n",
    "\n",
    "到目前为止，我们忽略了建立网络时需要做的以下这些事情：\n",
    "\n",
    "* 我们定义了网络架构，但没有指定输入维度。\n",
    "* 我们添加层时没有指定前一层的输出维度。\n",
    "* 我们在初始化参数时，甚至没有足够的信息来确定模型应该包含多少参数。\n",
    "\n",
    "你可能会对我们的代码能运行感到惊讶。\n",
    "毕竟，深度学习框架无法判断网络的输入维度是什么。\n",
    "这里的诀窍是框架的*延后初始化*（defers initialization），\n",
    "即直到数据第一次通过模型传递时，框架才会动态地推断出每个层的大小。\n",
    "\n",
    "在以后，当使用卷积神经网络时，\n",
    "由于输入维度（即图像的分辨率）将影响每个后续层的维数，\n",
    "有了该技术将更加方便。\n",
    "现在我们在编写代码时无须知道维度是什么就可以设置参数，\n",
    "这种能力可以大大简化定义和修改模型的任务。\n",
    "接下来，我们将更深入地研究初始化机制。\n",
    "\n",
    "## 实例化网络\n",
    "\n",
    "首先，让我们实例化一个多层感知机。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "此时，因为输入维数是未知的，所以网络不可能知道输入层权重的维数。\n",
    "因此，框架尚未初始化任何参数，我们通过尝试访问以下参数进行确认。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "接下来让我们将数据通过网络，最终使框架初始化参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "一旦我们知道输入维数是20，框架可以通过代入值20来识别第一层权重矩阵的形状。\n",
    "识别出第一层的形状后，框架处理第二层，依此类推，直到所有形状都已知为止。\n",
    "注意，在这种情况下，只有第一层需要延迟初始化，但是框架仍是按顺序初始化的。\n",
    "等到知道了所有的参数形状，框架就可以初始化参数。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 延后初始化使框架能够自动推断参数形状，使修改模型架构变得容易，避免了一些常见的错误。\n",
    "* 我们可以通过模型传递数据，使框架最终初始化参数。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 如果你指定了第一层的输入尺寸，但没有指定后续层的尺寸，会发生什么？是否立即进行初始化？\n",
    "1. 如果指定了不匹配的维度会发生什么？\n",
    "1. 如果输入具有不同的维度，你需要做什么？提示：查看参数绑定的相关内容。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1834)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([10, 10]) tensor([[ 0.1712, -0.0241, -0.1084, -0.2174,  0.0194, -0.1701, -0.1024,  0.0889,\n",
      "         -0.0523, -0.3108],\n",
      "        [ 0.1710, -0.2599, -0.1146, -0.3302,  0.0776,  0.0738, -0.0474, -0.0434,\n",
      "         -0.0680, -0.2903],\n",
      "        [ 0.2502, -0.1177, -0.2205, -0.2411, -0.0340,  0.0467,  0.0134,  0.0182,\n",
      "         -0.0901, -0.4104],\n",
      "        [ 0.1265, -0.0880, -0.1285, -0.3073,  0.0261, -0.0687, -0.0571,  0.0355,\n",
      "         -0.0855, -0.2938],\n",
      "        [ 0.1710, -0.0703, -0.2632, -0.1382,  0.0067, -0.1275, -0.0405,  0.0528,\n",
      "         -0.0593, -0.3937],\n",
      "        [ 0.1282, -0.0678, -0.2137, -0.2330, -0.0445, -0.0389,  0.0464,  0.0645,\n",
      "          0.0370, -0.3946],\n",
      "        [ 0.1873, -0.0081, -0.2224, -0.2069, -0.0740, -0.0464,  0.0651,  0.0878,\n",
      "          0.0647, -0.4088],\n",
      "        [ 0.2124, -0.0195, -0.1778, -0.2931, -0.1109,  0.0869,  0.0041,  0.0088,\n",
      "         -0.0105, -0.4157],\n",
      "        [ 0.2294, -0.1365, -0.1686, -0.2247, -0.0660, -0.0470, -0.0021, -0.0401,\n",
      "          0.0572, -0.4170],\n",
      "        [ 0.1330,  0.0612, -0.1816, -0.2549, -0.0557, -0.1349, -0.0153,  0.0231,\n",
      "         -0.0894, -0.3603]], grad_fn=<AddmmBackward0>)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# pytorch延迟初始化实战\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "print(net)\n",
    "X = torch.rand(10, 20)\n",
    "print(net(X).shape, net(X))\n",
    "print(net)\n",
    "\n",
    "# 两次print可以看出在传入数据后，网络模型大小最终完全确定。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d335c000319d31780868629cbb8d56d29bbfb551d0506479f49bae34a348ce5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
