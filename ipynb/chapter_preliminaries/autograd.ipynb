{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 自动微分\n",
    ":label:`sec_autograd`\n",
    "\n",
    "正如我们在 :numref:`sec_calculus`中所说的那样，求导是几乎所有深度学习优化算法的关键步骤。\n",
    "虽然求导的计算很简单，只需要一些基本的微积分。\n",
    "但对于复杂的模型，手工进行更新是一件很痛苦的事情（而且经常容易出错）。\n",
    "\n",
    "深度学习框架通过自动计算导数，即*自动微分*（automatic differentiation）来加快求导。\n",
    "实际中，根据我们设计的模型，系统会构建一个*计算图*（computational graph），\n",
    "来跟踪计算是哪些数据通过哪些操作组合起来产生输出。\n",
    "自动微分使系统能够随后反向传播梯度。\n",
    "这里，*反向传播*（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。\n",
    "\n",
    "## 一个简单的例子\n",
    "\n",
    "作为一个演示例子，(**假设我们想对函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量$\\mathbf{x}$求导**)。\n",
    "首先，我们创建变量`x`并为其分配一个初始值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "[**在我们计算$y$关于$\\mathbf{x}$的梯度之前，我们需要一个地方来存储梯度。**]\n",
    "重要的是，我们不会在每次对一个参数求导时都分配新的内存。\n",
    "因为我们经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。\n",
    "注意，一个标量函数关于向量$\\mathbf{x}$的梯度是向量，并且与$\\mathbf{x}$具有相同的形状。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)  # 等价于 `x = torch.arange(4.0, requires_grad=True)`\n",
    "print(x.grad)  # 默认值是None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "(**现在让我们计算$y$。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "`x`是一个长度为4的向量，计算`x`和`x`的点积，得到了我们赋值给`y`的标量输出。\n",
    "接下来，我们[**通过调用反向传播函数来自动计算`y`关于`x`每个分量的梯度**]，并打印这些梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于$\\mathbf{x}$的梯度应为$4\\mathbf{x}$。\n",
    "让我们快速验证这个梯度是否计算正确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "[**现在让我们计算`x`的另一个函数。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "## 非标量变量的反向传播\n",
    "\n",
    "当`y`不是标量时，向量`y`关于向量`x`的导数的最自然解释是一个矩阵。\n",
    "对于高阶和高维的`y`和`x`，求导的结果可以是一个高阶张量。\n",
    "\n",
    "然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括[**深度学习中**]），\n",
    "但当我们调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。\n",
    "这里(**，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用`backward`需要传入一个`gradient`参数，该参数指定微分函数关于`self`的梯度。\n",
    "# 在我们的例子中，我们只想求偏导数的和，所以传递一个1的梯度是合适的\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "## 分离计算\n",
    "\n",
    "有时，我们希望[**将某些计算移动到记录的计算图之外**]。\n",
    "例如，假设`y`是作为`x`的函数计算的，而`z`则是作为`y`和`x`的函数计算的。\n",
    "想象一下，我们想计算`z`关于`x`的梯度，但由于某种原因，我们希望将`y`视为一个常数，\n",
    "并且只考虑到`x`在`y`被计算后发挥的作用。\n",
    "\n",
    "在这里，我们可以分离`y`来返回一个新变量`u`，该变量与`y`具有相同的值，\n",
    "但丢弃计算图中如何计算`y`的任何信息。\n",
    "换句话说，梯度不会向后流经`u`到`x`。\n",
    "因此，下面的反向传播函数计算`z=u*x`关于`x`的偏导数，同时将`u`作为常数处理，\n",
    "而不是`z=x*x*x`关于`x`的偏导数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "由于记录了`y`的计算结果，我们可以随后在`y`上调用反向传播，\n",
    "得到`y=x*x`关于的`x`的导数，即`2*x`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "## Python控制流的梯度计算\n",
    "\n",
    "使用自动微分的一个好处是：\n",
    "[**即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度**]。\n",
    "在下面的代码中，`while`循环的迭代次数和`if`语句的结果都取决于输入`a`的值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "让我们计算梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor(-0.7049, requires_grad=True), d=tensor(-144368.6406, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "print(f'{a=}, {d=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "我们现在可以分析上面定义的`f`函数。\n",
    "请注意，它在其输入`a`中是分段线性的。\n",
    "换言之，对于任何`a`，存在某个常量标量`k`，使得`f(a)=k*a`，其中`k`的值取决于输入`a`。\n",
    "因此，我们可以用`d/a`验证梯度是否正确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 48
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 深度学习框架可以自动计算导数：我们首先将梯度附加到想要对其计算偏导数的变量上。然后我们记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 为什么计算二阶导数比一阶导数的开销要更大？\n",
    "1. 在运行反向传播函数之后，立即再次运行它，看看会发生什么。\n",
    "1. 在控制流的例子中，我们计算`d`关于`a`的导数，如果我们将变量`a`更改为随机向量或矩阵，会发生什么？\n",
    "1. 重新设计一个求控制流梯度的例子，运行并分析结果。\n",
    "1. 使$f(x)=\\sin(x)$，绘制$f(x)$和$\\frac{df(x)}{dx}$的图像，其中后者不使用$f'(x)=\\cos(x)$。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 50,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1759)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1: 计算二阶偏导需要先计算一阶偏导，计算量会更大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6737, -0.0202, -0.0507],\n",
      "        [-1.0454, -0.2893, -1.6816]], requires_grad=True)\n",
      "tensor([[ 0.2246, -0.0067, -0.0169],\n",
      "        [-0.3485, -0.0964, -0.5605]])\n",
      "tensor([[ 0.4492, -0.0135, -0.0338],\n",
      "        [-0.6970, -0.1928, -1.1210]])\n",
      "tensor([[ 0.6737, -0.0202, -0.0507],\n",
      "        [-1.0454, -0.2893, -1.6816]])\n"
     ]
    }
   ],
   "source": [
    "# A2:\n",
    "import torch\n",
    "x = torch.randn((2, 3), requires_grad=True)\n",
    "y = torch.square(x) - 1\n",
    "loss = y.mean()\n",
    "print(x)\n",
    "# 要加上`requires_grad=True`，不让计算图的中间变量释放，否则无法再次调用计算第二次梯度，\n",
    "loss.backward(retain_graph=True)\n",
    "print(x.grad)\n",
    "loss.backward(retain_graph=True)\n",
    "print(x.grad)\n",
    "loss.backward()\n",
    "print(x.grad)\n",
    "# 从结果可以看出来，就是把梯度再一次计算回传，叠加到上一次计算的梯度上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[ 0.0581,  0.0722, -1.6768],\n",
      "        [ 0.1125, -0.1217,  1.3385]], requires_grad=True), d=tensor([[  2976.3489,   3698.5854, -85854.5156],\n",
      "        [  5758.8228,  -6229.8755,  68530.7266]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# A3:\n",
    "import torch\n",
    "\n",
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "a = torch.randn(size=(2, 3), requires_grad=True)\n",
    "d = f(a)\n",
    "# 最后结果不是标量的话，要在backwards传入一个gradient参数\n",
    "d.backward(torch.ones_like(d))\n",
    "print(f'{a=}, {d=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor(0.0604, requires_grad=True), x.grad=tensor(2.0345), 1/2*x.item()**(-1/2)=2.034497595026457\n",
      "x=tensor(0.0604, requires_grad=True), x.grad=tensor(0.1208), 2*x.item()=0.12079685926437378\n"
     ]
    }
   ],
   "source": [
    "# A4:\n",
    "import torch\n",
    "\n",
    "def f(x, order):\n",
    "    if order == 1:\n",
    "        y = torch.sqrt(x)\n",
    "    elif order == 2:\n",
    "        y = torch.square(x)\n",
    "    return y\n",
    "\n",
    "x = torch.randn(size=(), requires_grad=True)\n",
    "y = f(x, 1)\n",
    "y.backward()\n",
    "print(f'{x=}, {x.grad=}, {1/2*x.item()**(-1/2)=}')\n",
    "# 清楚梯度，进行第二次计算\n",
    "x.grad.zero_()\n",
    "y = f(x, 2)\n",
    "y.backward()\n",
    "print(f'{x=}, {x.grad=}, {2*x.item()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7cd6390700>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A5 使用pytorch计算梯度\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import d2l\n",
    "import torch\n",
    "\n",
    "x = torch.arange(0.01, 10.0, 0.01, requires_grad=True)\n",
    "y = torch.sin(x)\n",
    "y.backward(torch.ones_like(y))\n",
    "\n",
    "plt.plot(x.detach().numpy(), x.grad.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d335c000319d31780868629cbb8d56d29bbfb551d0506479f49bae34a348ce5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
