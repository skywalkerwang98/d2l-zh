{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coordinated-extra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:07.966597Z",
     "iopub.status.busy": "2021-06-20T11:59:07.965869Z",
     "iopub.status.idle": "2021-06-20T11:59:15.771679Z",
     "shell.execute_reply": "2021-06-20T11:59:15.770249Z",
     "shell.execute_reply.started": "2021-06-20T11:54:41.449470Z"
    },
    "papermill": {
     "duration": 7.823524,
     "end_time": "2021-06-20T11:59:15.771835",
     "exception": false,
     "start_time": "2021-06-20T11:59:07.948311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: timm in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (0.6.7)\n",
      "Requirement already satisfied: torch>=1.4 in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from timm) (1.12.0)\n",
      "Requirement already satisfied: torchvision in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from timm) (0.13.0)\n",
      "Requirement already satisfied: typing_extensions in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from torch>=1.4->timm) (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from torchvision->timm) (1.22.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from torchvision->timm) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from requests->torchvision->timm) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from requests->torchvision->timm) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from requests->torchvision->timm) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/d2l/lib/python3.9/site-packages (from requests->torchvision->timm) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n",
    "# 代码中mixup的使用方法值得借鉴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hawaiian-wagner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:15.806145Z",
     "iopub.status.busy": "2021-06-20T11:59:15.805374Z",
     "iopub.status.idle": "2021-06-20T11:59:18.831268Z",
     "shell.execute_reply": "2021-06-20T11:59:18.830327Z",
     "shell.execute_reply.started": "2021-06-20T11:54:49.631613Z"
    },
    "papermill": {
     "duration": 3.044803,
     "end_time": "2021-06-20T11:59:18.831401",
     "exception": false,
     "start_time": "2021-06-20T11:59:15.786598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-effect",
   "metadata": {
    "papermill": {
     "duration": 0.014054,
     "end_time": "2021-06-20T11:59:18.860339",
     "exception": false,
     "start_time": "2021-06-20T11:59:18.846285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "executed-mother",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:18.897561Z",
     "iopub.status.busy": "2021-06-20T11:59:18.897003Z",
     "iopub.status.idle": "2021-06-20T11:59:18.938978Z",
     "shell.execute_reply": "2021-06-20T11:59:18.938345Z",
     "shell.execute_reply.started": "2021-06-20T11:54:52.752579Z"
    },
    "papermill": {
     "duration": 0.063908,
     "end_time": "2021-06-20T11:59:18.939109",
     "exception": false,
     "start_time": "2021-06-20T11:59:18.875201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = '/home/data/datasets/competitions/classify-leaves'\n",
    "train_path = os.path.join(dataset_path, 'train.csv')\n",
    "test_path = os.path.join(dataset_path, 'test.csv')\n",
    "train_csv = pd.read_csv(train_path)\n",
    "\n",
    "leaves_labels = sorted(list(set(train_csv['label'])))\n",
    "n_classes = len(leaves_labels)\n",
    "class_to_num = dict(zip(leaves_labels, range(n_classes)))\n",
    "num_to_class = {v : k for k, v in class_to_num.items()}\n",
    "\n",
    "# def train_test_split(data, train_size=.75):\n",
    "#     \"\"\" 分割数据集 旧的方法\n",
    "#     return: train_data_df, valid_data_df\n",
    "#     \"\"\"\n",
    "#     train_len = int(len(data) * train_size)\n",
    "#     indexs = np.arange(len(data))\n",
    "#     np.random.shuffle(indexs)\n",
    "\n",
    "#     return data.loc[indexs[:train_len]].reset_index(drop=True),\\\n",
    "#            data.loc[indexs[train_len:]].reset_index(drop=True)\n",
    "\n",
    "# train_csv, valid_csv = train_test_split(train_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-novelty",
   "metadata": {
    "papermill": {
     "duration": 0.013658,
     "end_time": "2021-06-20T11:59:18.967044",
     "exception": false,
     "start_time": "2021-06-20T11:59:18.953386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funded-congress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:19.007391Z",
     "iopub.status.busy": "2021-06-20T11:59:19.006864Z",
     "iopub.status.idle": "2021-06-20T11:59:19.010398Z",
     "shell.execute_reply": "2021-06-20T11:59:19.010012Z",
     "shell.execute_reply.started": "2021-06-20T11:54:52.795892Z"
    },
    "papermill": {
     "duration": 0.029483,
     "end_time": "2021-06-20T11:59:19.010499",
     "exception": false,
     "start_time": "2021-06-20T11:59:18.981016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReadData(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_data, transform=None):\n",
    "        super(ReadData, self).__init__()\n",
    "        self.dataset_path = '/home/data/datasets/competitions/classify-leaves'\n",
    "        self.data = csv_data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.dataset_path, self.data.loc[idx, \"image\"]))\n",
    "        label = class_to_num[self.data.loc[idx, \"label\"]]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def kfold(data, k=5):\n",
    "    \"\"\" K折交叉验证 \"\"\"\n",
    "    \n",
    "    KF = KFold(n_splits=k, shuffle=False)\n",
    "    for train_idxs, test_idxs in KF.split(data):\n",
    "        train_data = data.loc[train_idxs].reset_index(drop=True)\n",
    "        valid_data = data.loc[test_idxs].reset_index(drop=True)\n",
    "        train_iter = torch.utils.data.DataLoader(\n",
    "            ReadData(train_data, train_transform), batch_size=64,\n",
    "            shuffle=True, num_workers=d2l.get_dataloader_workers(), pin_memory=True\n",
    "        )\n",
    "\n",
    "        valid_iter = torch.utils.data.DataLoader(\n",
    "            ReadData(valid_data, valid_transform), batch_size=64,\n",
    "            shuffle=True, num_workers=d2l.get_dataloader_workers(), pin_memory=True\n",
    "        )\n",
    "        \n",
    "        yield train_iter, valid_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-humidity",
   "metadata": {
    "papermill": {
     "duration": 0.01358,
     "end_time": "2021-06-20T11:59:19.037953",
     "exception": false,
     "start_time": "2021-06-20T11:59:19.024373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instrumental-shore",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:19.071388Z",
     "iopub.status.busy": "2021-06-20T11:59:19.070894Z",
     "iopub.status.idle": "2021-06-20T11:59:19.074396Z",
     "shell.execute_reply": "2021-06-20T11:59:19.073986Z",
     "shell.execute_reply.started": "2021-06-20T11:54:52.811337Z"
    },
    "papermill": {
     "duration": 0.022779,
     "end_time": "2021-06-20T11:59:19.074506",
     "exception": false,
     "start_time": "2021-06-20T11:59:19.051727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    \"\"\" Mixup 数据增强 -> 随机叠加两张图像 \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    # 这里和下面一样，都是使用一个batch的数据随机替换到另一个batch中\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "piano-conditioning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:19.111847Z",
     "iopub.status.busy": "2021-06-20T11:59:19.111202Z",
     "iopub.status.idle": "2021-06-20T11:59:19.114273Z",
     "shell.execute_reply": "2021-06-20T11:59:19.113653Z",
     "shell.execute_reply.started": "2021-06-20T11:54:52.823339Z"
    },
    "papermill": {
     "duration": 0.026056,
     "end_time": "2021-06-20T11:59:19.114418",
     "exception": false,
     "start_time": "2021-06-20T11:59:19.088362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    \"\"\" 随机裁剪 \"\"\"\n",
    "    W, H = size[2], size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    \"\"\" Cutmix 数据增强 -> 随机对主图像进行裁剪, 加上噪点图像\n",
    "    W: 添加裁剪图像宽\n",
    "    H: 添加裁剪图像高\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "    \n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "welsh-while",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:19.151608Z",
     "iopub.status.busy": "2021-06-20T11:59:19.151015Z",
     "iopub.status.idle": "2021-06-20T11:59:29.332695Z",
     "shell.execute_reply": "2021-06-20T11:59:29.331656Z",
     "shell.execute_reply.started": "2021-06-20T11:54:52.838038Z"
    },
    "papermill": {
     "duration": 10.203505,
     "end_time": "2021-06-20T11:59:29.332841",
     "exception": false,
     "start_time": "2021-06-20T11:59:19.129336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_models(k=5):\n",
    "    models = {}\n",
    "    for mk in range(k):\n",
    "        model = timm.create_model(\"resnest50d_4s2x40d\", True, drop_rate=.5)\n",
    "        # 在特征提取层之后添加一个mlp用于微调\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(model.fc.in_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(.3),\n",
    "            nn.Linear(512, len(num_to_class))\n",
    "        )\n",
    "        # for param in model.layer4.parameters():\n",
    "        #     if isinstance(param, nn.Conv2d):\n",
    "        #         nn.init.xavier_normal_(param.weight)\n",
    "        # for param in model.fc.parameters():\n",
    "        #     if isinstance(param, nn.Linear):\n",
    "        #         nn.init.kaiming_normal_(param.weight)\n",
    "        # model.load_state_dict(torch.load(f\"../input/resnest50/Resnest50d.pth\"))\n",
    "        # 固定前面几层\n",
    "        # 这里是只固定了前六层\n",
    "        for i, param in enumerate(model.children()):\n",
    "            if i == 6:\n",
    "                break\n",
    "            param.requires_grad = False\n",
    "\n",
    "        model.cuda()\n",
    "\n",
    "        opt = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, 10, T_mult=2)\n",
    "        models[f\"model_{mk}\"] = {\n",
    "            \"model\": model,\n",
    "            \"opt\": opt,\n",
    "            \"scheduler\": scheduler,\n",
    "            \"last_acc\": .97\n",
    "        }\n",
    "    \n",
    "    return models\n",
    "\n",
    "# 一共集成了5个模型，和交叉验证的份数一致\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "major-auckland",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:29.367466Z",
     "iopub.status.busy": "2021-06-20T11:59:29.365752Z",
     "iopub.status.idle": "2021-06-20T11:59:29.368029Z",
     "shell.execute_reply": "2021-06-20T11:59:29.368409Z",
     "shell.execute_reply.started": "2021-06-20T11:55:03.295254Z"
    },
    "papermill": {
     "duration": 0.021152,
     "end_time": "2021-06-20T11:59:29.368556",
     "exception": false,
     "start_time": "2021-06-20T11:59:29.347404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_criterion(pred, y_a, y_b, lam):\n",
    "    c = nn.CrossEntropyLoss()\n",
    "    return lam * c(pred, y_a) + (1 - lam) * c(pred, y_b)\n",
    "criterion = mixup_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-impossible",
   "metadata": {
    "papermill": {
     "duration": 0.013799,
     "end_time": "2021-06-20T11:59:29.396174",
     "exception": false,
     "start_time": "2021-06-20T11:59:29.382375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "former-knock",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T11:59:29.439802Z",
     "iopub.status.busy": "2021-06-20T11:59:29.438998Z",
     "iopub.status.idle": "2021-06-20T14:16:07.972679Z",
     "shell.execute_reply": "2021-06-20T14:16:07.973095Z"
    },
    "papermill": {
     "duration": 8198.563252,
     "end_time": "2021-06-20T14:16:07.973269",
     "exception": false,
     "start_time": "2021-06-20T11:59:29.410017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_708527/4276473864.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cut_w = np.int(W * cut_rat)\n",
      "/tmp/ipykernel_708527/4276473864.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cut_h = np.int(H * cut_rat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-Fold1 —— Train Loss: 5.168, Train Accuracy: 0.83%, Valid Accuracy: 3.52%, Learning Rate: 0.000005, Time Out: 81.8s\n",
      "Epoch 1-Fold2 —— Train Loss: 5.162, Train Accuracy: 0.83%, Valid Accuracy: 2.58%, Learning Rate: 0.000005, Time Out: 80.3s\n",
      "Epoch 1-Fold3 —— Train Loss: 5.159, Train Accuracy: 0.97%, Valid Accuracy: 4.07%, Learning Rate: 0.000005, Time Out: 80.5s\n",
      "Epoch 1-Fold4 —— Train Loss: 5.164, Train Accuracy: 0.90%, Valid Accuracy: 3.85%, Learning Rate: 0.000005, Time Out: 80.5s\n",
      "Epoch 1-Fold5 —— Train Loss: 5.162, Train Accuracy: 0.79%, Valid Accuracy: 3.26%, Learning Rate: 0.000005, Time Out: 80.4s\n",
      "Epoch 1 —— Train Accuracy: 0.86%, Valid Accuracy: 3.46%\n",
      "\n",
      "Epoch 2-Fold1 —— Train Loss: 5.128, Train Accuracy: 1.78%, Valid Accuracy: 11.86%, Learning Rate: 0.000005, Time Out: 80.7s\n",
      "Epoch 2-Fold2 —— Train Loss: 5.112, Train Accuracy: 2.21%, Valid Accuracy: 5.17%, Learning Rate: 0.000005, Time Out: 80.6s\n",
      "Epoch 2-Fold3 —— Train Loss: 5.102, Train Accuracy: 2.31%, Valid Accuracy: 6.28%, Learning Rate: 0.000005, Time Out: 80.5s\n",
      "Epoch 2-Fold4 —— Train Loss: 5.109, Train Accuracy: 2.23%, Valid Accuracy: 7.37%, Learning Rate: 0.000005, Time Out: 80.6s\n",
      "Epoch 2-Fold5 —— Train Loss: 5.107, Train Accuracy: 2.53%, Valid Accuracy: 6.46%, Learning Rate: 0.000005, Time Out: 80.6s\n",
      "Epoch 2 —— Train Accuracy: 2.21%, Valid Accuracy: 7.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    for epoch in range(10):\n",
    "        flod_train_acc = []\n",
    "        flod_valid_acc = []\n",
    "        for k, (train_iter, valid_iter) in enumerate(kfold(train_csv, 5)):\n",
    "            model = models[f\"model_{k}\"][\"model\"]\n",
    "            opt = models[f\"model_{k}\"][\"opt\"]\n",
    "            scheduler = models[f\"model_{k}\"][\"scheduler\"]\n",
    "            s = time.time()\n",
    "            model.train()\n",
    "            train_loss = []\n",
    "            train_acc = 0\n",
    "            length = 0\n",
    "            for x, y in train_iter:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                random_num = np.random.random()\n",
    "                # 随机选取mixup的方式\n",
    "                if random_num <= 1/3:\n",
    "                    x, y_a, y_b, lam = mixup_data(x, y, use_cuda=True)\n",
    "                elif random_num <= 2/3:\n",
    "                    x, y_a, y_b, lam = cutmix_data(x, y, use_cuda=True)\n",
    "                else:\n",
    "                    x, y_a, y_b, lam = mixup_data(x, y, alpha=0, use_cuda=True)\n",
    "                x, y_a, y_b = map(torch.autograd.Variable, (x, y_a, y_b))\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y_a, y_b, lam)\n",
    "                train_loss.append(loss.item())\n",
    "                predict = output.argmax(dim=1)\n",
    "                length += x.shape[0]\n",
    "                # 因为是对不同batch之间的进行替换，可以使用下面的方法去求解\n",
    "                train_acc += lam * (predict == y_a).cpu().sum().item() + \\\n",
    "                            (1 - lam) * (predict == y_b).cpu().sum().item()\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            model.eval()\n",
    "            valid_acc = []\n",
    "            with torch.no_grad():\n",
    "                for x, y in valid_iter:\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                    pre_x = model(x)\n",
    "                    valid_acc.append((pre_x.argmax(1) == y).float().mean().item())\n",
    "\n",
    "            k_train_ = train_acc / length\n",
    "            k_valid_ = sum(valid_acc) / len(valid_acc)\n",
    "            if k_valid_ > models[f\"model_{k}\"][\"last_acc\"]:\n",
    "                torch.save(model.state_dict(), f\"./kaggle_leaves_competition_model/Resnest50d_{k}.pth\")\n",
    "                models[f\"model_{k}\"][\"last_acc\"] = k_valid_\n",
    "\n",
    "            response = f\"Epoch {epoch + 1}-Fold{k + 1} —— \" + \\\n",
    "                    f\"Train Loss: {sum(train_loss) / len(train_loss) :.3f}, \" + \\\n",
    "                    f\"Train Accuracy: {k_train_ * 100 :.2f}%, \" + \\\n",
    "                    f\"Valid Accuracy: {k_valid_ * 100 :.2f}%, \" + \\\n",
    "                    f\"Learning Rate: {opt.param_groups[0]['lr'] :.6f}, \" + \\\n",
    "                    f\"Time Out: {time.time() - s :.1f}s\"\n",
    "            print(response)\n",
    "            flod_train_acc.append(k_train_)\n",
    "            flod_valid_acc.append(k_valid_)\n",
    "\n",
    "        t_accuracy = np.mean(flod_train_acc)\n",
    "        v_accuracy = np.mean(flod_valid_acc)\n",
    "        print(f\"Epoch {epoch + 1} —— \" + \\\n",
    "            f\"Train Accuracy: {t_accuracy * 100 :.2f}%, \" + \\\n",
    "            f\"Valid Accuracy: {v_accuracy * 100 :.2f}%\\n\")\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-tampa",
   "metadata": {
    "papermill": {
     "duration": 0.02645,
     "end_time": "2021-06-20T14:16:08.026234",
     "exception": false,
     "start_time": "2021-06-20T14:16:07.999784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bulgarian-independence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T14:16:08.085173Z",
     "iopub.status.busy": "2021-06-20T14:16:08.084682Z",
     "iopub.status.idle": "2021-06-20T14:16:08.102895Z",
     "shell.execute_reply": "2021-06-20T14:16:08.102210Z",
     "shell.execute_reply.started": "2021-06-20T11:55:14.531310Z"
    },
    "papermill": {
     "duration": 0.049963,
     "end_time": "2021-06-20T14:16:08.103003",
     "exception": false,
     "start_time": "2021-06-20T14:16:08.053040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(\"../input/classify-leaves/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cheap-factor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T14:16:08.163042Z",
     "iopub.status.busy": "2021-06-20T14:16:08.162378Z",
     "iopub.status.idle": "2021-06-20T14:16:08.165467Z",
     "shell.execute_reply": "2021-06-20T14:16:08.165847Z",
     "shell.execute_reply.started": "2021-06-20T11:55:14.828492Z"
    },
    "papermill": {
     "duration": 0.036228,
     "end_time": "2021-06-20T14:16:08.165975",
     "exception": false,
     "start_time": "2021-06-20T14:16:08.129747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReadData(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_data, transform=None):\n",
    "        super(ReadData, self).__init__()\n",
    "        self.data = csv_data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(\"../input/classify-leaves/\" + self.data.loc[idx, \"image\"])\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    ReadData(test_csv, valid_transform), batch_size=64,\n",
    "    num_workers=2, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cleared-clerk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T14:16:08.228743Z",
     "iopub.status.busy": "2021-06-20T14:16:08.227254Z",
     "iopub.status.idle": "2021-06-20T14:18:05.342724Z",
     "shell.execute_reply": "2021-06-20T14:18:05.342158Z",
     "shell.execute_reply.started": "2021-06-20T11:56:15.766281Z"
    },
    "papermill": {
     "duration": 117.147557,
     "end_time": "2021-06-20T14:18:05.342876",
     "exception": false,
     "start_time": "2021-06-20T14:16:08.195319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict = None\n",
    "with torch.no_grad():\n",
    "    for x in test_iter:\n",
    "        x = x.cuda()\n",
    "        p = torch.zeros((x.size()[0], len(class_to_num)))\n",
    "        for k in range(5):\n",
    "            model = models[f\"model_{k}\"][\"model\"]\n",
    "            # 这里也相当于集成学习，集成不同的fold训练出的model\n",
    "            p += model(x).detach().cpu()\n",
    "        if predict is None:\n",
    "            predict = p.argmax(1)\n",
    "        else:\n",
    "            predict = torch.cat([predict, p.argmax(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grand-cowboy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T14:18:05.406193Z",
     "iopub.status.busy": "2021-06-20T14:18:05.405705Z",
     "iopub.status.idle": "2021-06-20T14:18:05.730356Z",
     "shell.execute_reply": "2021-06-20T14:18:05.729658Z",
     "shell.execute_reply.started": "2021-06-20T11:58:18.813175Z"
    },
    "papermill": {
     "duration": 0.359366,
     "end_time": "2021-06-20T14:18:05.730495",
     "exception": false,
     "start_time": "2021-06-20T14:18:05.371129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/classify-leaves/sample_submission.csv\")\n",
    "df.label = predict.cpu().numpy()\n",
    "df.label = df.label.apply(lambda x: num_to_class[x])\n",
    "df.to_csv(\"/kaggle/working/result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8344.993585,
   "end_time": "2021-06-20T14:18:07.650202",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-20T11:59:02.656617",
   "version": "2.3.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d335c000319d31780868629cbb8d56d29bbfb551d0506479f49bae34a348ce5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
